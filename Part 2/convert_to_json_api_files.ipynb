{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "208a0efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 解析文件: 2.txt ===\n",
      "原始开头片段: 0. article title: \"Mathematical models for job-shop scheduling problems with routing and process plan flexibility\"  1. problem description: \"FJSP consists of a set of n independent jobs J = {j_i}_{i=1 ...\n",
      "\n",
      "--- 解析第 1 个模型 ---\n",
      "解析到 article_title: Mathematical models for job-shop scheduling problems with routing and process plan flexibility\n",
      "解析到问题描述(截断): FJSP consists of a set of n independent jobs J = {j_i}_{i=1}^n, each having its own processing order ...\n",
      "解析到 11 个参数\n",
      "解析到 6 个决策变量\n",
      "解析到 8 条约束\n",
      "\n",
      "--- 解析第 2 个模型 ---\n",
      "解析到 article_title: Mathematical models for job-shop scheduling problems with routing and process plan flexibility\n",
      "解析到问题描述(截断): The FJSP-PPF considers multiple process plans for jobs by excluding the final assumption of FJSP. Th ...\n",
      "解析到 11 个参数\n",
      "解析到 6 个决策变量\n",
      "解析到 8 条约束\n",
      "✅ 已保存：/Users/yoosi/Desktop/Capstone/json_file/2_model1.json\n",
      "✅ 已保存：/Users/yoosi/Desktop/Capstone/json_file/2_model2.json\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "从 txt（示例格式见截图）解析调度问题，并用 DeepSeek 辅助补充信息。\n",
    "变更点：\n",
    "- 用 DeepSeek API 替代原来的 Ollama 调用；\n",
    "- 批量处理 Input 目录下的 .txt，输出到 output_json；\n",
    "- 顶层 JSON 新增 article_title。\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List\n",
    "\n",
    "# ========================== 路径配置（按需改） ==========================\n",
    "# ——手动指定要处理的 txt 完整路径——\n",
    "FILES = [\n",
    "    \"2.txt\",\n",
    "]\n",
    "OUT_DIR = Path.home() / \"/Users/yoosi/Desktop/Capstone/json_file\"  # 批量输出 .json 的目录\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "# =====================================================================\n",
    "\n",
    "# ======================= DeepSeek（OpenAI兼容） =======================\n",
    "try:\n",
    "    from openai import OpenAI\n",
    "except ImportError as e:\n",
    "    raise ImportError(\"需要安装 openai>=1.0.0 ：pip install --upgrade openai\") from e\n",
    "\n",
    "DEEPSEEK_API_KEY = os.getenv(\"DEEPSEEK_API_KEY\", \"sk-ca02b34094134bd8902281716aad4a65\")\n",
    "DS_MODEL = \"deepseek-chat\"  # 通用对话模型\n",
    "\n",
    "ds_client = OpenAI(\n",
    "    api_key=DEEPSEEK_API_KEY,\n",
    "    base_url=\"https://api.deepseek.com\"\n",
    ")\n",
    "\n",
    "\n",
    "def ds_chat(prompt: str, max_retries: int = 2) -> str:\n",
    "    \"\"\"最小封装：发送 user 消息，返回文本内容\"\"\"\n",
    "    last_err = None\n",
    "    for _ in range(max_retries + 1):\n",
    "        try:\n",
    "            resp = ds_client.chat.completions.create(\n",
    "                model=DS_MODEL,\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                temperature=0\n",
    "            )\n",
    "            return (resp.choices[0].message.content or \"\").strip()\n",
    "        except Exception as e:\n",
    "            last_err = e\n",
    "    raise RuntimeError(f\"DeepSeek 调用失败: {last_err}\")\n",
    "# =====================================================================\n",
    "\n",
    "\n",
    "def parse_txt_file(file_path: Path) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    从 txt 文件中解析调度问题数据，支持多个模型\n",
    "    返回模型列表\n",
    "    \"\"\"\n",
    "    content = file_path.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "    print(f\"\\n=== 解析文件: {file_path.name} ===\")\n",
    "    print(\"原始开头片段:\", content[:200].replace(\"\\n\", \" \") + \" ...\")\n",
    "\n",
    "    # 按模型分割 - 查找所有以 \"0. article title:\" 开头的模型\n",
    "    model_pattern = r'0\\.\\s*article\\s+title:\\s*\"[^\"]*\".*?(?=\\s*0\\.\\s*article\\s+title:|\\Z)'\n",
    "    model_matches = re.findall(model_pattern, content, re.DOTALL | re.I)\n",
    "    \n",
    "    models = []\n",
    "    \n",
    "    for i, model_content in enumerate(model_matches):\n",
    "        print(f\"\\n--- 解析第 {i+1} 个模型 ---\")\n",
    "        result: Dict[str, Any] = {}\n",
    "        \n",
    "        # 0) 文章标题 - 修正正则表达式，去掉多余的反斜杠\n",
    "        title_match = re.search(r'0\\.\\s*article\\s+title:\\s*\"([^\"]+)\"', model_content, flags=re.I)\n",
    "        if title_match:\n",
    "            result['article_title'] = title_match.group(1).strip()\n",
    "            print(\"解析到 article_title:\", result['article_title'])\n",
    "        else:\n",
    "            result['article_title'] = \"\"\n",
    "            print(\"未解析到 article_title\")\n",
    "\n",
    "        # 1) 问题描述 - 修正正则表达式\n",
    "        desc_match = re.search(r'1\\.\\s*problem\\s+description:\\s*\"([^\"]*)\"', model_content, flags=re.I)\n",
    "        if desc_match:\n",
    "            result['problem_description'] = desc_match.group(1)\n",
    "            print(\"解析到问题描述(截断):\", result['problem_description'][:100], \"...\")\n",
    "        else:\n",
    "            result['problem_description'] = \"\"\n",
    "\n",
    "        # 2) 参数 - 修正正则表达式\n",
    "        params_match = re.search(r'2\\.\\s*parameters:\\s*(\\[.*?\\])', model_content, re.DOTALL | re.I)\n",
    "        if params_match:\n",
    "            try:\n",
    "                result['parameters'] = json.loads(params_match.group(1))\n",
    "                print(f\"解析到 {len(result['parameters'])} 个参数\")\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(\"参数解析错误:\", e)\n",
    "                result['parameters'] = []\n",
    "        else:\n",
    "            result['parameters'] = []\n",
    "\n",
    "        # 3) 决策变量 - 修正正则表达式\n",
    "        vars_match = re.search(r'3\\.\\s*decision\\s+variables:\\s*(\\[.*?\\])', model_content, re.DOTALL | re.I)\n",
    "        if vars_match:\n",
    "            try:\n",
    "                result['decision_variables'] = json.loads(vars_match.group(1))\n",
    "                print(f\"解析到 {len(result['decision_variables'])} 个决策变量\")\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(\"决策变量解析错误:\", e)\n",
    "                result['decision_variables'] = []\n",
    "        else:\n",
    "            result['decision_variables'] = []\n",
    "\n",
    "        # 4) 目标函数 - 修正正则表达式\n",
    "        obj_match = re.search(r'4\\.\\s*objective\\s+function:\\s*(\\{.*?\\})(?=\\s*;|\\s*$|\\s*5\\.)', model_content, re.DOTALL | re.I)\n",
    "        if not obj_match:\n",
    "            obj_match = re.search(r'4\\.\\s*objective\\s+function:\\s*(\\{.*\\})', model_content, re.DOTALL | re.I)\n",
    "        if obj_match:\n",
    "            obj_str = obj_match.group(1)\n",
    "            try:\n",
    "                result['objective_function'] = json.loads(obj_str)\n",
    "            except json.JSONDecodeError:\n",
    "                # 尝试手动抓取两个字段\n",
    "                f = re.search(r'\"function\"\\s*:\\s*\"([^\"]*)\"', obj_str)\n",
    "                d = re.search(r'\"description\"\\s*:\\s*\"([^\"]*)\"', obj_str)\n",
    "                result['objective_function'] = {\n",
    "                    \"function\": f.group(1) if f else \"\",\n",
    "                    \"description\": d.group(1) if d else \"\"\n",
    "                }\n",
    "        else:\n",
    "            result['objective_function'] = {}\n",
    "\n",
    "        # 5) 约束 - 修正正则表达式\n",
    "        cons_match = re.search(r'5\\.\\s*constraints:\\s*(\\[.*?\\])', model_content, re.DOTALL | re.I)\n",
    "        if cons_match:\n",
    "            try:\n",
    "                result['constraints'] = json.loads(cons_match.group(1))\n",
    "                print(f\"解析到 {len(result['constraints'])} 条约束\")\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(\"约束解析错误:\", e)\n",
    "                result['constraints'] = []\n",
    "        else:\n",
    "            result['constraints'] = []\n",
    "        \n",
    "        models.append(result)\n",
    "    \n",
    "    return models\n",
    "\n",
    "def extract_related_variables_with_llm(constraint_function: str,\n",
    "                                       constraint_description: str,\n",
    "                                       decision_variables: List[Dict[str, str]]) -> List[str]:\n",
    "    \"\"\"\n",
    "    用 DeepSeek 判断约束里出现了哪些决策变量符号。\n",
    "    仅返回在给定列表中的符号。\n",
    "    \"\"\"\n",
    "    var_symbols = [v.get('symbol', '') for v in decision_variables if isinstance(v, dict)]\n",
    "    prompt = (\n",
    "        \"给定约束：\\n\"\n",
    "        f\"表达式：{constraint_function}\\n\"\n",
    "        f\"描述：{constraint_description}\\n\\n\"\n",
    "        f\"候选决策变量符号列表：{var_symbols}\\n\\n\"\n",
    "        \"请返回该约束中实际出现的符号，**只返回 JSON 数组**，例如：[\\\"C_{ijq}\\\", \\\"u_{ijq}\\\"]。\"\n",
    "    )\n",
    "    try:\n",
    "        text = ds_chat(prompt)\n",
    "        # 优先尝试 JSON 解析\n",
    "        try:\n",
    "            arr = json.loads(text)\n",
    "            if isinstance(arr, list):\n",
    "                return [s for s in arr if s in var_symbols]\n",
    "        except json.JSONDecodeError:\n",
    "            pass\n",
    "        # 不可解析 JSON 时做包含匹配作为兜底\n",
    "        found = [s for s in var_symbols if s and s in text]\n",
    "        return found\n",
    "    except Exception as e:\n",
    "        print(\"提取相关变量失败：\", e)\n",
    "        return []\n",
    "\n",
    "\n",
    "def convert_to_standard_json_format(parsed: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    将解析结果整理为统一 JSON。\n",
    "    顶层新增 article_title；其余结构尽量保持你原来的风格。\n",
    "    \"\"\"\n",
    "    problem_description = parsed.get('problem_description', '')\n",
    "    parameters = parsed.get('parameters', [])\n",
    "    decision_variables = parsed.get('decision_variables', [])\n",
    "    objective_function = parsed.get('objective_function', {})\n",
    "    constraints = parsed.get('constraints', [])\n",
    "    article_title = parsed.get('article_title', '').strip()\n",
    "\n",
    "    # 让模型根据描述生成一个标题/类型（若需要）\n",
    "    title_prompt = (\n",
    "        \"Based on this problem description, generate a concise title for this scheduling problem and the type of scheduling problem (Job shop/flow shop/Hybrid flow shop/Flexible job shop/Distributed hybrid flow shop/Distributed permutation flow shop/Distributed job shop/Distributed flow shop/Distributed assembly job shop/Distributed flexible job shop, and so on) this problem belongs to.\\n\"\n",
    "        f\"Description: {problem_description[:300]}...\\n\"\n",
    "        \"Output format: Title|Type\"\n",
    "    )\n",
    "    try:\n",
    "        title_type = ds_chat(title_prompt).split(\"|\")\n",
    "        gen_title = title_type[0].strip() if len(title_type) > 0 else \"Scheduling Problem\"\n",
    "        problem_type = title_type[1].strip() if len(title_type) > 1 else \"Scheduling\"\n",
    "    except Exception:\n",
    "        gen_title = \"Scheduling Problem\"\n",
    "        problem_type = \"Scheduling\"\n",
    "\n",
    "    # 输出结构（顶层加 article_title）\n",
    "    result: Dict[str, Any] = {\n",
    "        \"article_title\": article_title or gen_title,  # 优先用解析到的文章标题\n",
    "        \"title\": gen_title,                           # 你之前生成的“问题标题”\n",
    "        \"type\": problem_type,\n",
    "        \"description\": problem_description,\n",
    "        \"Nomenclature\": {\n",
    "            \"Parameters\": [],\n",
    "            \"Decision Variables\": [],\n",
    "            \"Domain terms\": {\n",
    "                \"Makespan\": \"In production scheduling problems, the makespan is the maximum completion time of jobs\"\n",
    "            }\n",
    "        },\n",
    "        \"Formulation\": {\n",
    "            \"Objective Function\": {\n",
    "                \"function\": \"\",\n",
    "                \"gurobi_code\": \"\",\n",
    "                \"description\": \"\"\n",
    "            },\n",
    "            \"Constraints\": []\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # 参数\n",
    "    for p in parameters:\n",
    "        result[\"Nomenclature\"][\"Parameters\"].append({\n",
    "            \"symbol\": p.get(\"symbol\", \"\"),\n",
    "            \"definition\": p.get(\"definition\", \"\")\n",
    "        })\n",
    "\n",
    "    # 决策变量（简单判别类型）\n",
    "    for v in decision_variables:\n",
    "        defin = v.get(\"definition\", \"\")\n",
    "        vtype = \"Binary\" if any(k in defin.lower() for k in [\"binary\", \"equals 1\", \"0 otherwise\", \"1 if\"]) else \"Continuous\"\n",
    "        result[\"Nomenclature\"][\"Decision Variables\"].append({\n",
    "            \"symbol\": v.get(\"symbol\", \"\"),\n",
    "            \"definition\": defin,\n",
    "            \"type\": vtype\n",
    "        })\n",
    "\n",
    "    # 目标函数\n",
    "    if isinstance(objective_function, dict) and (objective_function.get(\"function\") or objective_function.get(\"description\")):\n",
    "        result[\"Formulation\"][\"Objective Function\"] = {\n",
    "            \"function\": objective_function.get(\"function\", \"\"),\n",
    "            \"description\": objective_function.get(\"description\", \"\")\n",
    "        }\n",
    "    else:\n",
    "        result[\"Formulation\"][\"Objective Function\"] = {\n",
    "            \"function\": \"minimize C_max and sum of T_i\",\n",
    "            \"description\": \"Minimize makespan and total tardiness simultaneously\"\n",
    "        }\n",
    "\n",
    "    # 约束（用模型提取相关决策变量）\n",
    "    for i, c in enumerate(constraints):\n",
    "        func = c.get(\"function\", \"\")\n",
    "        if not isinstance(func, list):\n",
    "            func = [func]\n",
    "        desc = c.get(\"description\", \"\")\n",
    "        text_for_vars = \" \".join(func)\n",
    "        related_vars = extract_related_variables_with_llm(text_for_vars, desc, result[\"Nomenclature\"][\"Decision Variables\"])\n",
    "\n",
    "        # 参数关联（简单包含匹配）\n",
    "        related_params: List[str] = []\n",
    "        simple_text = re.sub(r'[{}_\\s]', '', text_for_vars)\n",
    "        for p in result[\"Nomenclature\"][\"Parameters\"]:\n",
    "            sym = p[\"symbol\"]\n",
    "            if not sym:\n",
    "                continue\n",
    "            if sym in text_for_vars or re.sub(r'[{}_\\s]', '', sym) in simple_text:\n",
    "                related_params.append(sym)\n",
    "\n",
    "        result[\"Formulation\"][\"Constraints\"].append({\n",
    "            \"function\": func,\n",
    "            \"description\": desc,\n",
    "            \"related Parameters\": related_params,\n",
    "            \"related Decision Variables\": related_vars\n",
    "        })\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def process_one_txt(txt_path: Path, out_json_path: Path) -> None:\n",
    "    models = parse_txt_file(txt_path)\n",
    "    \n",
    "    # 如果只有一个模型，保持原来的文件名\n",
    "    if len(models) == 1:\n",
    "        result = convert_to_standard_json_format(models[0])\n",
    "        out_json_path.write_text(json.dumps(result, indent=2, ensure_ascii=False), encoding=\"utf-8\")\n",
    "        print(f\"✅ 已保存：{out_json_path}\")\n",
    "    else:\n",
    "        # 多个模型，为每个模型创建单独的文件\n",
    "        for i, model in enumerate(models):\n",
    "            # 修改输出文件名，添加模型索引\n",
    "            model_out_path = out_json_path.parent / f\"{out_json_path.stem}_model{i+1}{out_json_path.suffix}\"\n",
    "            result = convert_to_standard_json_format(model)\n",
    "            model_out_path.write_text(json.dumps(result, indent=2, ensure_ascii=False), encoding=\"utf-8\")\n",
    "            print(f\"✅ 已保存：{model_out_path}\")\n",
    "\n",
    "def main():\n",
    "    outdir = OUT_DIR.expanduser().resolve()\n",
    "    outdir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for pth in FILES:\n",
    "        f = Path(pth).expanduser().resolve()\n",
    "        if not f.exists():\n",
    "            print(f\"❌ Not found: {f}\")\n",
    "            continue\n",
    "        out_path = outdir / f.with_suffix(\".json\").name\n",
    "        process_one_txt(f, out_path)\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a468df-cffd-41d3-b7d8-1f2ff2fadbd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
